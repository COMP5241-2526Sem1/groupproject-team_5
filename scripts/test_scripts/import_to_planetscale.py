#!/usr/bin/env python3
"""
å¯¼å…¥æ•°æ®åˆ°äº‘ç«¯ MySQL æ•°æ®åº“ï¼ˆRailway/PlanetScaleç­‰ï¼‰
ä» export_local_data.py å¯¼å‡ºçš„ JSON æ–‡ä»¶å¯¼å…¥
"""

import pymysql
import json
import os
import sys
from datetime import datetime

def import_data(json_file):
    """å¯¼å…¥æ•°æ®åˆ° PlanetScale"""
    print("=" * 60)
    print("ğŸ“¥ PlanetScale æ•°æ®å¯¼å…¥å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(json_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return False
    
    file_size = os.path.getsize(json_file) / 1024
    print(f"\nğŸ“ æ•°æ®æ–‡ä»¶: {json_file}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
    
    # PlanetScale é…ç½®
    config = {
        'host': os.getenv('MYSQL_HOST'),
        'port': int(os.getenv('MYSQL_PORT', 3306)),
        'user': os.getenv('MYSQL_USER'),
        'password': os.getenv('MYSQL_PASSWORD'),
        'database': os.getenv('MYSQL_DATABASE'),
        'charset': 'utf8mb4'
    }
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    missing = [k for k, v in config.items() if v is None and k != 'port']
    if missing:
        print(f"\nâŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing)}")
        print("\nè¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        print("  export MYSQL_HOST=your-db.psdb.cloud")
        print("  export MYSQL_USER=your_username")
        print("  export MYSQL_PASSWORD=pscale_pw_xxx")
        print("  export MYSQL_DATABASE=qa-platform")
        return False
    
    print(f"\nğŸ” è¿æ¥é…ç½®:")
    print(f"   ä¸»æœº: {config['host']}:{config['port']}")
    print(f"   æ•°æ®åº“: {config['database']}")
    print(f"   ç”¨æˆ·: {config['user']}")
    
    # æ£€æµ‹æ˜¯å¦æ˜¯ PlanetScale
    is_planetscale = 'psdb.cloud' in config['host']
    if is_planetscale:
        print("   âœ… æ£€æµ‹åˆ° PlanetScale è¿æ¥")
        config['ssl'] = {'ssl': True}
    
    try:
        print(f"\nğŸ“¡ è¿æ¥åˆ°æ•°æ®åº“...")
        conn = pymysql.connect(**config)
        cursor = conn.cursor()
        print("âœ… è¿æ¥æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return False
    
    # è¯»å–æ•°æ®
    print(f"\nğŸ“– è¯»å–æ•°æ®æ–‡ä»¶...")
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… è¯»å–æˆåŠŸï¼ŒåŒ…å« {len(data)} ä¸ªè¡¨")
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return False
    
    # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
    print(f"\nğŸ” æ£€æŸ¥è¡¨ç»“æ„...")
    cursor.execute("SHOW TABLES")
    existing_tables = [row[0] for row in cursor.fetchall()]
    print(f"   æ•°æ®åº“ä¸­æœ‰ {len(existing_tables)} ä¸ªè¡¨")
    
    if not existing_tables:
        print("\nâš ï¸  æ•°æ®åº“ä¸­æ²¡æœ‰è¡¨ï¼")
        print("   è¯·å…ˆè¿è¡Œ: python init_db.py")
        return False
    
    # å¯¼å…¥é¡ºåºï¼ˆè€ƒè™‘å¤–é”®ä¾èµ–ï¼‰
    # æ ¹æ®ä½ çš„æ¨¡å‹è°ƒæ•´é¡ºåº
    import_order = ['user', 'course', 'enrollment', 'activity', 'question', 'answer', 'reply']
    
    # æ·»åŠ æ•°æ®ä¸­æœ‰ä½†ä¸åœ¨é¡ºåºåˆ—è¡¨çš„è¡¨
    for table in data.keys():
        if table not in import_order and table in existing_tables:
            import_order.append(table)
    
    print(f"\nğŸ“¥ å¼€å§‹å¯¼å…¥...")
    print(f"   å¯¼å…¥é¡ºåº: {' â†’ '.join(import_order)}")
    
    total_success = 0
    total_error = 0
    
    for table in import_order:
        if table not in data:
            continue
        
        rows = data[table]
        
        if not rows:
            print(f"\nâš ï¸  è·³è¿‡ç©ºè¡¨: {table}")
            continue
        
        if table not in existing_tables:
            print(f"\nâš ï¸  è¡¨ {table} ä¸å­˜åœ¨äºç›®æ ‡æ•°æ®åº“ï¼Œè·³è¿‡")
            continue
        
        print(f"\nğŸ“¦ å¯¼å…¥è¡¨: {table}")
        print(f"   å…± {len(rows)} æ¡è®°å½•")
        
        # è·å–åˆ—å
        columns = list(rows[0].keys())
        placeholders = ', '.join(['%s'] * len(columns))
        columns_str = ', '.join([f'`{col}`' for col in columns])
        
        # æ„å»º INSERT è¯­å¥
        sql = f"INSERT IGNORE INTO {table} ({columns_str}) VALUES ({placeholders})"
        
        success_count = 0
        error_count = 0
        errors = []
        
        # æ‰¹é‡æ’å…¥
        batch_size = 100
        for i in range(0, len(rows), batch_size):
            batch = rows[i:i+batch_size]
            
            for row in batch:
                try:
                    values = [row[col] for col in columns]
                    cursor.execute(sql, values)
                    success_count += 1
                except Exception as e:
                    error_count += 1
                    if error_count <= 3:  # åªè®°å½•å‰3ä¸ªé”™è¯¯
                        errors.append(str(e))
            
            # æ¯æ‰¹æäº¤ä¸€æ¬¡
            conn.commit()
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = min(i + batch_size, len(rows))
            percent = (progress / len(rows)) * 100
            print(f"   è¿›åº¦: {progress}/{len(rows)} ({percent:.1f}%)", end='\r')
        
        print()  # æ¢è¡Œ
        print(f"   âœ… æˆåŠŸ: {success_count}")
        if error_count > 0:
            print(f"   âš ï¸  å¤±è´¥: {error_count}")
            if errors:
                print(f"   é”™è¯¯ç¤ºä¾‹:")
                for err in errors[:3]:
                    print(f"     - {err}")
        
        total_success += success_count
        total_error += error_count
    
    cursor.close()
    conn.close()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å¯¼å…¥å®Œæˆï¼")
    print("=" * 60)
    print(f"âœ… æˆåŠŸå¯¼å…¥: {total_success} æ¡è®°å½•")
    if total_error > 0:
        print(f"âš ï¸  å¤±è´¥: {total_error} æ¡è®°å½•")
    print("=" * 60)
    
    print(f"\nä¸‹ä¸€æ­¥:")
    print(f"  è¿è¡ŒéªŒè¯: python verify_migration.py")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python import_to_planetscale.py <jsonæ–‡ä»¶>")
        print("\nç¤ºä¾‹:")
        print("  python import_to_planetscale.py data_backup_20251110_153000.json")
        print("\næœ€è¿‘çš„å¤‡ä»½æ–‡ä»¶:")
        
        # æŸ¥æ‰¾å¤‡ä»½æ–‡ä»¶
        import glob
        backups = sorted(glob.glob("data_backup_*.json"), reverse=True)
        if backups:
            for backup in backups[:5]:
                size = os.path.getsize(backup) / 1024
                print(f"  - {backup} ({size:.2f} KB)")
        else:
            print("  æœªæ‰¾åˆ°å¤‡ä»½æ–‡ä»¶")
        
        sys.exit(1)
    
    json_file = sys.argv[1]
    success = import_data(json_file)
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
