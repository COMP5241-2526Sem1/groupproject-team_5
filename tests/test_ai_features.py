#!/usr/bin/env python3
"""
AIåŠŸèƒ½æµ‹è¯•æ¨¡å—
æµ‹è¯•QAå¹³å°çš„AIé—®é¢˜ç”Ÿæˆã€å†…å®¹åˆ†æç­‰åŠŸèƒ½
"""

import os
import sys
import time
import json
from typing import List, Dict

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.ai_utils import generate_questions, analyze_content_quality, generate_questions_fallback

class AITester:
    """AIåŠŸèƒ½æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.test_results = []
        self.passed = 0
        self.failed = 0
        
    def log_test(self, test_name: str, passed: bool, message: str = ""):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        status = "âœ… PASS" if passed else "âŒ FAIL"
        result = f"{status} | {test_name}"
        if message:
            result += f" | {message}"
        
        print(result)
        self.test_results.append({
            'name': test_name,
            'passed': passed,
            'message': message
        })
        
        if passed:
            self.passed += 1
        else:
            self.failed += 1
    
    def test_environment_setup(self):
        """æµ‹è¯•ç¯å¢ƒé…ç½®"""
        print("\nğŸ”§ æµ‹è¯•ç¯å¢ƒé…ç½®...")
        
        # æ£€æŸ¥APIå¯†é’¥
        ark_key = os.environ.get('ARK_API_KEY')
        openai_key = os.environ.get('OPENAI_API_KEY')
        
        if ark_key:
            self.log_test("ARK APIå¯†é’¥æ£€æµ‹", True, "ARK APIå¯†é’¥å·²é…ç½®")
            return "ark"
        elif openai_key:
            self.log_test("OpenAI APIå¯†é’¥æ£€æµ‹", True, "OpenAI APIå¯†é’¥å·²é…ç½®")
            return "openai"
        else:
            self.log_test("APIå¯†é’¥æ£€æµ‹", True, "æœªé…ç½®APIå¯†é’¥ï¼Œå°†ä½¿ç”¨å›é€€æ¨¡å¼")
            return "fallback"
    
    def test_fallback_question_generation(self):
        """æµ‹è¯•å›é€€æ¨¡å¼é—®é¢˜ç”Ÿæˆ"""
        print("\nğŸ¯ æµ‹è¯•å›é€€æ¨¡å¼é—®é¢˜ç”Ÿæˆ...")
        
        test_text = """
        Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå…·æœ‰ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½ã€‚
        Pythonæ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹ã€å‡½æ•°å¼ç¼–ç¨‹ç­‰å¤šç§ç¼–ç¨‹èŒƒå¼ã€‚
        åœ¨æ•°æ®ç§‘å­¦ã€äººå·¥æ™ºèƒ½ã€Webå¼€å‘ç­‰é¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ã€‚
        """
        
        try:
            questions = generate_questions_fallback(test_text)
            
            # æ£€æŸ¥æ˜¯å¦è¿”å›äº†é—®é¢˜
            if questions and len(questions) > 0:
                self.log_test("å›é€€æ¨¡å¼ç”Ÿæˆé—®é¢˜", True, f"ç”Ÿæˆäº†{len(questions)}ä¸ªé—®é¢˜")
                for i, q in enumerate(questions, 1):
                    print(f"   é—®é¢˜{i}: {q}")
            else:
                self.log_test("å›é€€æ¨¡å¼ç”Ÿæˆé—®é¢˜", False, "æœªç”Ÿæˆä»»ä½•é—®é¢˜")
                
        except Exception as e:
            self.log_test("å›é€€æ¨¡å¼ç”Ÿæˆé—®é¢˜", False, f"å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def test_ai_question_generation(self, api_type: str):
        """æµ‹è¯•AIé—®é¢˜ç”Ÿæˆ"""
        print(f"\nğŸ¤– æµ‹è¯•AIé—®é¢˜ç”Ÿæˆ ({api_type.upper()})...")
        
        test_text = """
        æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè®©è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ è§„å¾‹ï¼Œ
        è€Œä¸éœ€è¦æ˜¾å¼ç¼–ç¨‹ã€‚ä¸»è¦åŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰ç§ç±»å‹ã€‚
        ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæ— ç›‘ç£å­¦ä¹ ä»æœªæ ‡æ³¨æ•°æ®ä¸­å‘ç°æ¨¡å¼ï¼Œ
        å¼ºåŒ–å­¦ä¹ é€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥ã€‚
        """
        
        try:
            start_time = time.time()
            questions = generate_questions(test_text)
            end_time = time.time()
            
            response_time = end_time - start_time
            
            if questions and len(questions) > 0:
                self.log_test(f"{api_type.upper()} APIå“åº”", True, f"å“åº”æ—¶é—´: {response_time:.2f}ç§’")
                self.log_test(f"{api_type.upper()} é—®é¢˜ç”Ÿæˆ", True, f"ç”Ÿæˆäº†{len(questions)}ä¸ªé—®é¢˜")
                
                print(f"   ğŸ“ ç”Ÿæˆçš„é—®é¢˜:")
                for i, q in enumerate(questions, 1):
                    print(f"   {i}. {q}")
                    
                # æ£€æŸ¥é—®é¢˜è´¨é‡
                self.check_question_quality(questions)
                
            else:
                self.log_test(f"{api_type.upper()} é—®é¢˜ç”Ÿæˆ", False, "æœªç”Ÿæˆä»»ä½•é—®é¢˜")
                
        except Exception as e:
            self.log_test(f"{api_type.upper()} APIè°ƒç”¨", False, f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
            print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
    
    def check_question_quality(self, questions: List[str]):
        """æ£€æŸ¥é—®é¢˜è´¨é‡"""
        print(f"\nğŸ“Š é—®é¢˜è´¨é‡åˆ†æ...")
        
        # æ£€æŸ¥é—®é¢˜é•¿åº¦
        avg_length = sum(len(q) for q in questions) / len(questions)
        length_ok = 10 <= avg_length <= 200
        self.log_test("é—®é¢˜é•¿åº¦æ£€æŸ¥", length_ok, f"å¹³å‡é•¿åº¦: {avg_length:.1f}å­—ç¬¦")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é—®å·
        has_question_marks = sum(1 for q in questions if '?' in q or 'ï¼Ÿ' in q)
        question_mark_ok = has_question_marks >= len(questions) * 0.5
        self.log_test("é—®å·æ£€æŸ¥", question_mark_ok, f"{has_question_marks}/{len(questions)}ä¸ªé—®é¢˜åŒ…å«é—®å·")
        
        # æ£€æŸ¥é‡å¤æ€§
        unique_questions = len(set(questions))
        uniqueness_ok = unique_questions == len(questions)
        self.log_test("é—®é¢˜å”¯ä¸€æ€§", uniqueness_ok, f"{unique_questions}/{len(questions)}ä¸ªé—®é¢˜æ˜¯å”¯ä¸€çš„")
        
        # æ£€æŸ¥å…³é”®è¯è¦†ç›–
        keywords = ['ä»€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å“ªäº›', 'what', 'how', 'why', 'which']
        has_keywords = sum(1 for q in questions for kw in keywords if kw.lower() in q.lower())
        keyword_ok = has_keywords > 0
        self.log_test("å…³é”®è¯æ£€æŸ¥", keyword_ok, f"åŒ…å«{has_keywords}ä¸ªé—®é¢˜å…³é”®è¯")
    
    def test_content_analysis(self):
        """æµ‹è¯•å†…å®¹è´¨é‡åˆ†æ"""
        print(f"\nğŸ“ˆ æµ‹è¯•å†…å®¹è´¨é‡åˆ†æ...")
        
        test_content = """
        è¿™æ˜¯ä¸€ä¸ªè¯¦ç»†çš„å›ç­”ï¼Œè§£é‡Šäº†Pythonç¼–ç¨‹è¯­è¨€çš„ç‰¹ç‚¹ã€‚
        Pythonå…·æœ‰ç®€æ´çš„è¯­æ³•ï¼Œæ˜“äºå­¦ä¹ å’Œä½¿ç”¨ã€‚
        å®ƒæ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼ï¼ŒåŒ…æ‹¬é¢å‘å¯¹è±¡å’Œå‡½æ•°å¼ç¼–ç¨‹ã€‚
        Pythonåœ¨æ•°æ®ç§‘å­¦ã€AIã€Webå¼€å‘ç­‰é¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ã€‚
        """
        
        try:
            analysis = analyze_content_quality(test_content)
            
            if analysis and isinstance(analysis, dict):
                self.log_test("å†…å®¹åˆ†æåŠŸèƒ½", True, "æˆåŠŸåˆ†æå†…å®¹è´¨é‡")
                
                print(f"   ğŸ“Š åˆ†æç»“æœ:")
                for key, value in analysis.items():
                    print(f"   - {key}: {value}")
                    
                # æ£€æŸ¥åˆ†æç»“æœçš„å®Œæ•´æ€§
                expected_keys = ['length', 'readability', 'completeness', 'accuracy']
                has_all_keys = all(key in analysis for key in expected_keys)
                self.log_test("åˆ†æç»“æœå®Œæ•´æ€§", has_all_keys, f"åŒ…å«{len(analysis)}ä¸ªåˆ†æç»´åº¦")
                
            else:
                self.log_test("å†…å®¹åˆ†æåŠŸèƒ½", False, "åˆ†æç»“æœæ ¼å¼é”™è¯¯")
                
        except Exception as e:
            self.log_test("å†…å®¹åˆ†æåŠŸèƒ½", False, f"åˆ†æå¤±è´¥: {str(e)}")
    
    def test_api_error_handling(self):
        """æµ‹è¯•APIé”™è¯¯å¤„ç†"""
        print(f"\nğŸš¨ æµ‹è¯•é”™è¯¯å¤„ç†...")
        
        # æµ‹è¯•ç©ºæ–‡æœ¬
        try:
            questions = generate_questions("")
            empty_text_ok = isinstance(questions, list)
            self.log_test("ç©ºæ–‡æœ¬å¤„ç†", empty_text_ok, "æ­£ç¡®å¤„ç†ç©ºæ–‡æœ¬è¾“å…¥")
        except Exception as e:
            self.log_test("ç©ºæ–‡æœ¬å¤„ç†", False, f"ç©ºæ–‡æœ¬å¤„ç†å¤±è´¥: {str(e)}")
        
        # æµ‹è¯•è¶…é•¿æ–‡æœ¬
        try:
            long_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚" * 1000  # éå¸¸é•¿çš„æ–‡æœ¬
            questions = generate_questions(long_text)
            long_text_ok = isinstance(questions, list)
            self.log_test("è¶…é•¿æ–‡æœ¬å¤„ç†", long_text_ok, "æ­£ç¡®å¤„ç†è¶…é•¿æ–‡æœ¬")
        except Exception as e:
            self.log_test("è¶…é•¿æ–‡æœ¬å¤„ç†", True, f"é¢„æœŸçš„é”™è¯¯å¤„ç†: {str(e)}")
    
    def test_performance(self, api_type: str):
        """æµ‹è¯•æ€§èƒ½"""
        print(f"\nâš¡ æ€§èƒ½æµ‹è¯• ({api_type.upper()})...")
        
        test_texts = [
            "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚",
            "æœºå™¨å­¦ä¹ åŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚",
            "Webå¼€å‘ä¸­å¸¸ç”¨çš„æ¡†æ¶æœ‰Djangoã€Flaskã€FastAPIç­‰ã€‚"
        ]
        
        total_time = 0
        successful_calls = 0
        
        for i, text in enumerate(test_texts, 1):
            try:
                start_time = time.time()
                questions = generate_questions(text)
                end_time = time.time()
                
                call_time = end_time - start_time
                total_time += call_time
                successful_calls += 1
                
                print(f"   æµ‹è¯•{i}: {call_time:.2f}ç§’, ç”Ÿæˆ{len(questions)}ä¸ªé—®é¢˜")
                
            except Exception as e:
                print(f"   æµ‹è¯•{i}: å¤±è´¥ - {str(e)}")
        
        if successful_calls > 0:
            avg_time = total_time / successful_calls
            performance_ok = avg_time < 10.0  # 10ç§’å†…å®Œæˆ
            self.log_test("å¹³å‡å“åº”æ—¶é—´", performance_ok, f"{avg_time:.2f}ç§’/æ¬¡")
            self.log_test("æˆåŠŸç‡", successful_calls == len(test_texts), f"{successful_calls}/{len(test_texts)}æ¬¡æˆåŠŸ")
        else:
            self.log_test("æ€§èƒ½æµ‹è¯•", False, "æ‰€æœ‰APIè°ƒç”¨éƒ½å¤±è´¥äº†")
    
    def run_interactive_test(self):
        """äº¤äº’å¼æµ‹è¯•"""
        print(f"\nğŸ® äº¤äº’å¼æµ‹è¯•...")
        print("æ‚¨å¯ä»¥è¾“å…¥è‡ªå®šä¹‰æ–‡æœ¬æ¥æµ‹è¯•AIé—®é¢˜ç”ŸæˆåŠŸèƒ½ã€‚")
        
        while True:
            user_input = input("\nè¯·è¾“å…¥æµ‹è¯•æ–‡æœ¬ (è¾“å…¥'quit'é€€å‡º): ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                break
            
            if not user_input:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡æœ¬ï¼")
                continue
            
            try:
                print("ğŸ¤– æ­£åœ¨ç”Ÿæˆé—®é¢˜...")
                start_time = time.time()
                questions = generate_questions(user_input)
                end_time = time.time()
                
                print(f"âœ… ç”Ÿæˆå®Œæˆ (ç”¨æ—¶: {end_time - start_time:.2f}ç§’)")
                print(f"ğŸ“ ç”Ÿæˆäº†{len(questions)}ä¸ªé—®é¢˜:")
                
                for i, q in enumerate(questions, 1):
                    print(f"   {i}. {q}")
                    
            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print(f"\n" + "="*60)
        print(f"ğŸ æµ‹è¯•æ€»ç»“")
        print(f"="*60)
        print(f"âœ… é€šè¿‡: {self.passed}")
        print(f"âŒ å¤±è´¥: {self.failed}")
        print(f"ğŸ“Š æ€»è®¡: {self.passed + self.failed}")
        
        if self.failed == 0:
            print(f"ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
        else:
            print(f"âš ï¸  æœ‰{self.failed}ä¸ªæµ‹è¯•å¤±è´¥")
            
        success_rate = (self.passed / (self.passed + self.failed)) * 100 if (self.passed + self.failed) > 0 else 0
        print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
        
        return self.failed == 0

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ QAå¹³å°AIåŠŸèƒ½æµ‹è¯•å¯åŠ¨")
    print("=" * 60)
    
    tester = AITester()
    
    # ç¯å¢ƒæ£€æµ‹
    api_type = tester.test_environment_setup()
    
    # åŸºç¡€åŠŸèƒ½æµ‹è¯•
    tester.test_fallback_question_generation()
    
    # AIåŠŸèƒ½æµ‹è¯•ï¼ˆå¦‚æœæœ‰APIå¯†é’¥ï¼‰
    if api_type in ['ark', 'openai']:
        tester.test_ai_question_generation(api_type)
        tester.test_performance(api_type)
    
    # å†…å®¹åˆ†ææµ‹è¯•
    tester.test_content_analysis()
    
    # é”™è¯¯å¤„ç†æµ‹è¯•
    tester.test_api_error_handling()
    
    # æ‰“å°æµ‹è¯•æ€»ç»“
    success = tester.print_summary()
    
    # è¯¢é—®æ˜¯å¦è¿›è¡Œäº¤äº’å¼æµ‹è¯•
    if api_type in ['ark', 'openai']:
        choice = input(f"\nğŸ’¡ æ˜¯å¦è¿›è¡Œäº¤äº’å¼æµ‹è¯•ï¼Ÿ(y/n): ").strip().lower()
        if choice in ['y', 'yes', 'æ˜¯']:
            tester.run_interactive_test()
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
